{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Data Frame\") \\\n",
    "        .config(\"spark.ui.port\", \"4050\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringJSONRDD = sc.parallelize((\n",
    "    \"\"\"{\"id\": \"123\", \"name\": \"Katie\", \"age\": 19, \"eyeColor\": \"brown\"}\"\"\",\n",
    "    \"\"\"{\"id\": \"234\", \"name\": \"Michael\", \"age\": 22, \"eyeColor\": \"green\"}\"\"\",\n",
    "    \"\"\"{\"id\": \"345\", \"name\": \"Simone\", \"age\": 23, \"eyeColor\": \"blue\"}\"\"\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "swimmersJSON = spark.read.json(stringJSONRDD) # spark.read 는 narrow transformation function 이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmersJSON.createOrReplaceTempView('swimmersJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n",
      "['{\"id\": \"123\", \"name\": \"Katie\", \"age\": 19, \"eyeColor\": \"brown\"}', '{\"id\": \"234\", \"name\": \"Michael\", \"age\": 22, \"eyeColor\": \"green\"}', '{\"id\": \"345\", \"name\": \"Simone\", \"age\": 23, \"eyeColor\": \"blue\"}']\n"
     ]
    }
   ],
   "source": [
    "print(type(stringJSONRDD))\n",
    "print(stringJSONRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "[Row(age=19, eyeColor='brown', id='123', name='Katie'), Row(age=22, eyeColor='green', id='234', name='Michael'), Row(age=23, eyeColor='blue', id='345', name='Simone')]\n",
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(swimmersJSON))\n",
    "print(swimmersJSON.collect())\n",
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+\n",
      "| id|   name|age|eyeColor|\n",
      "+---+-------+---+--------+\n",
      "|123|  Katie| 19|   brown|\n",
      "|234|Michael| 22|   green|\n",
      "|345| Simone| 23|    blue|\n",
      "+---+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "stringCSVRDD = sc.parallelize(\n",
    "    [\n",
    "        (123, 'Katie', 19, 'brown'),\n",
    "        (234, 'Michael', 22, 'green'),\n",
    "        (345, 'Simone', 23, 'blue'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "schemaString = 'id name age eyeColor'\n",
    "schema = StructType([\n",
    "    StructField('id', LongType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', LongType(), True),\n",
    "    StructField('eyeColor', StringType(), True),\n",
    "])\n",
    "\n",
    "swimmers = spark.createDataFrame(stringCSVRDD, schema)\n",
    "swimmers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=123, name='Katie', age=19, eyeColor='brown'),\n",
       " Row(id=234, name='Michael', age=22, eyeColor='green'),\n",
       " Row(id=345, name='Simone', age=23, eyeColor='blue')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swimmers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=123, name='Katie', age=19, eyeColor='brown')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swimmers.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+\n",
      "| id|   name|age|eyeColor|\n",
      "+---+-------+---+--------+\n",
      "|123|  Katie| 19|   brown|\n",
      "|234|Michael| 22|   green|\n",
      "|345| Simone| 23|    blue|\n",
      "+---+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmers.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+---+\n",
      "| id|   name|age|eyeColor|one|\n",
      "+---+-------+---+--------+---+\n",
      "|123|  Katie| 19|   brown|  1|\n",
      "|234|Michael| 22|   green|  1|\n",
      "|345| Simone| 23|    blue|  1|\n",
      "+---+-------+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "swimmers.withColumn('one', lit(1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
