{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Spark ML\") \\\n",
    "        .config(\"spark.ui.port\", \"4050\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- BloodPressure: string (nullable = true)\n",
      " |-- SkinThickness: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = spark.read.format('csv').option('header', 'true').load('../../data/input5/diabetes.csv')\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- Glucose: float (nullable = true)\n",
      " |-- BloodPressure: float (nullable = true)\n",
      " |-- SkinThickness: float (nullable = true)\n",
      " |-- Insulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: float (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Outcome: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('Pregnancies', FloatType(), True),\n",
    "    StructField('Glucose', FloatType(), True),\n",
    "    StructField('BloodPressure', FloatType(), True),\n",
    "    StructField('SkinThickness', FloatType(), True),\n",
    "    StructField('Insulin', FloatType(), True),\n",
    "    StructField('BMI', FloatType(), True),\n",
    "    StructField('DiabetesPedigreeFunction', FloatType(), True),\n",
    "    StructField('Age', IntegerType(), True),\n",
    "    StructField('Outcome', IntegerType(), True),\n",
    "])\n",
    "\n",
    "raw_data = spark.read.format('csv').option('header', 'true').schema(schema).load('../../data/input5/diabetes.csv')\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|          Glucose|     BloodPressure|     SkinThickness|           Insulin|              BMI|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|              768|               768|               768|               768|              768|\n",
      "|   mean|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.99257813890775|\n",
      "| stddev|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803|7.884160293010772|\n",
      "|    min|              0.0|               0.0|               0.0|               0.0|              0.0|\n",
      "|    max|            199.0|             122.0|              99.0|             846.0|             67.1|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.describe(['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|          Glucose|     BloodPressure|     SkinThickness|           Insulin|              BMI|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|              768|               768|               768|               768|              768|\n",
      "|   mean|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.99257813890775|\n",
      "| stddev|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803|7.884160293010772|\n",
      "|    min|              0.0|               0.0|               0.0|               0.0|              0.0|\n",
      "|    25%|             99.0|              62.0|               0.0|               0.0|             27.3|\n",
      "|    50%|            117.0|              72.0|              23.0|              29.0|             32.0|\n",
      "|    75%|            140.0|              80.0|              32.0|             127.0|             36.6|\n",
      "|    max|            199.0|             122.0|              99.0|             846.0|             67.1|\n",
      "+-------+-----------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.select('Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.rdd.map(lambda row: 1 if sum([c == None for c in row]) > 0 else 0)\\\n",
    "            .reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "raw_data.rdd.map(lambda row: 1 if sum([row[c] == 0 for c in prep_cols]) > 0 else 0)\\\n",
    "            .reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|        6.0|  148.0|         72.0|         35.0|   null|33.6|                   0.627| 50|      1|\n",
      "|        1.0|   85.0|         66.0|         29.0|   null|26.6|                   0.351| 31|      0|\n",
      "|        8.0|  183.0|         64.0|         null|   null|23.3|                   0.672| 32|      1|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167| 21|      0|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "\n",
    "for c in prep_cols:\n",
    "    raw_data = raw_data.withColumn(c, fn.when(fn.col(c) == 0, None).otherwise(fn.col(c)))\n",
    "\n",
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+---------------------+------------------+------------------+\n",
      "|   Glucose_missing|BloodPressure_missing|SkinThickness_missing|   Insulin_missing|       BMI_missing|\n",
      "+------------------+---------------------+---------------------+------------------+------------------+\n",
      "|0.9934895833333334|   0.9544270833333334|   0.7044270833333334|0.5130208333333334|0.9856770833333334|\n",
      "+------------------+---------------------+---------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.select(*[(fn.count(c) / fn.count('*')).alias(c + '_missing') for c in prep_cols]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+---------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|  Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+---------+----+------------------------+---+-------+\n",
      "|        6.0|  148.0|         72.0|         35.0|155.54822|33.6|                   0.627| 50|      1|\n",
      "|        1.0|   85.0|         66.0|         29.0|155.54822|26.6|                   0.351| 31|      0|\n",
      "|        8.0|  183.0|         64.0|     29.15342|155.54822|23.3|                   0.672| 32|      1|\n",
      "|        1.0|   89.0|         66.0|         23.0|     94.0|28.1|                   0.167| 21|      0|\n",
      "|        0.0|  137.0|         40.0|         35.0|    168.0|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+---------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=prep_cols, outputCols=prep_cols)\n",
    "model = imputer.fit(raw_data)\n",
    "raw_data = model.transform(raw_data)\n",
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = raw_data.columns\n",
    "cols.remove('Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+\n",
      "|features                                                                                       |\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "|[6.0,148.0,72.0,35.0,155.5482177734375,33.599998474121094,0.6269999742507935,50.0]             |\n",
      "|[1.0,85.0,66.0,29.0,155.5482177734375,26.600000381469727,0.35100001096725464,31.0]             |\n",
      "|[8.0,183.0,64.0,29.153419494628906,155.5482177734375,23.299999237060547,0.671999990940094,32.0]|\n",
      "|[1.0,89.0,66.0,23.0,94.0,28.100000381469727,0.16699999570846558,21.0]                          |\n",
      "|[0.0,137.0,40.0,35.0,168.0,43.099998474121094,2.2880001068115234,33.0]                         |\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "raw_data = assembler.transform(raw_data)\n",
    "raw_data.select('features').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[6.0,148.0,72.0,3...|[1.78063837321943...|\n",
      "|[1.0,85.0,66.0,29...|[0.29677306220323...|\n",
      "|[8.0,183.0,64.0,2...|[2.37418449762590...|\n",
      "|[1.0,89.0,66.0,23...|[0.29677306220323...|\n",
      "|[0.0,137.0,40.0,3...|[0.0,4.5012560836...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withStd=True, withMean=False)\n",
    "raw_data = standard_scaler.fit(raw_data).transform(raw_data)\n",
    "raw_data.select('features', 'scaled_features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613, 155)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = raw_data.randomSplit([0.8, 0.2], seed=37)\n",
    "train.count(), test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Outcome|prediction|\n",
      "+-------+----------+\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol='Outcome', featuresCol='scaled_features', maxIter=100)\n",
    "model = lr.fit(train)\n",
    "predict_train = model.transform(train)\n",
    "predict_test = model.transform(test)\n",
    "predict_test.select('Outcome', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------+----------------------------------------+----------+\n",
      "|Outcome|rawPrediction                           |probability                             |prediction|\n",
      "+-------+----------------------------------------+----------------------------------------+----------+\n",
      "|0      |[2.6606282231648404,-2.6606282231648404]|[0.9346630414096359,0.06533695859036415]|0.0       |\n",
      "|0      |[1.951762315123215,-1.951762315123215]  |[0.8756386772239592,0.12436132277604084]|0.0       |\n",
      "|0      |[2.5766438051311003,-2.5766438051311003]|[0.929343203851855,0.07065679614814502] |0.0       |\n",
      "|0      |[1.204333872708819,-1.204333872708819]  |[0.7692948579791697,0.23070514202083026]|0.0       |\n",
      "|0      |[2.9971688375226133,-2.9971688375226133]|[0.9524460603511284,0.04755393964887156]|0.0       |\n",
      "+-------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select('Outcome', 'rawPrediction', 'probability', 'prediction').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.rdd.map(lambda row: 1 if row['Outcome'] == row['prediction'] else 0)\\\n",
    "                .reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.rdd.map(lambda row: 1 if row['Outcome'] == row['prediction'] else 0).reduce(lambda x, y: x + y) / predict_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
