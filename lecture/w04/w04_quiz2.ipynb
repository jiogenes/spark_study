{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('Quiz2') \\\n",
    "        .config('spark.ui.port', '4050') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터\n",
    "- points1.csv: 10개의 점ID와 2차원 (xy좌표) 점의 집합\n",
    "- points2.csv: 100,000개의 2차원 (xy좌표) 점의 집합\n",
    "  \n",
    "문제\n",
    "- points1의 각 점 X에 대해 다른 points1의 점들 중 X를 가장 가까운 점으로 하는 points2의 점의 개수를 구하시오.\n",
    "- 즉, 점 X의 ReverseClosestPoint(X)를 {u∈points2|∀v∈points1,d(u,X)≤d(u,v)}라는 집합으로 정의하였을 때 각 점 X에 대해 ReverseClosestPoint(X)의 크기를 출력하는 것이 문제임.\n",
    "  \n",
    "출력 \n",
    "- 점ID, |ReverseClosestPoint(X)|\n",
    "  \n",
    "HINT\n",
    "- points1은 broadcasting하고 ReverseClosestPoint(X)의 크기는 accumulator로 카운트 하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3332310446739237, 0.8816789623129827),\n",
       " (1, 0.7180093769486705, 0.9637912346703899),\n",
       " (2, 0.8116248725383151, 0.13696859152848095),\n",
       " (3, 0.32558100044331795, 0.503730643753619),\n",
       " (4, 0.8771663414457561, 0.7076376276477696),\n",
       " (5, 0.19388260220851417, 0.5493842742220786),\n",
       " (6, 0.27167090531975013, 0.43894203635672935),\n",
       " (7, 0.07368066232777415, 0.47765482567815376),\n",
       " (8, 0.9228510563432439, 0.05714995929075273),\n",
       " (9, 0.9140180890494094, 0.13546962101450588)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point1 = sc.textFile('../../data/input2/points1.csv')\n",
    "point1 = point1.map(lambda x: eval(x)).collect()\n",
    "point1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_point_set = sc.broadcast(point1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.3605768939144025,0.41427340085592523',\n",
       " '0.49981193499908516,0.044445721194083965',\n",
       " '0.04282837853009491,0.8789469946706773',\n",
       " '0.26220726052348475,0.8162745170777618',\n",
       " '0.0223264683905956,0.7485061647576708']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point2 = sc.textFile('../../data/input2/points2.csv')\n",
    "point2.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x, y):\n",
    "    return ((x[0] - y[0])**2 + (x[1] - y[1])**2)**0.5\n",
    "\n",
    "def find_min_dist(point1, point2):\n",
    "    point2 = list(map(float, point2.split(',')))\n",
    "    minimum = 987654321\n",
    "    minimum_idx = -1\n",
    "    for idx, x, y in point1:\n",
    "        d = dist((x, y), point2)\n",
    "        if minimum > d:\n",
    "            minimum = d\n",
    "            minimum_idx = idx\n",
    "    return minimum_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '0.8071618868229837,0.9549318616231292'),\n",
       " (4, '0.8483020262221963,0.7199779417791973'),\n",
       " (6, '0.391731441893985,0.2280996037290972'),\n",
       " (2, '0.7217786652575899,0.3599210126660518'),\n",
       " (7, '0.006756387685526333,0.41676697341323576')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point2.map(lambda x: (find_min_dist(bc_point_set.value, x), x)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 8319),\n",
       " (4, 15936),\n",
       " (6, 14729),\n",
       " (2, 15088),\n",
       " (7, 8222),\n",
       " (3, 10818),\n",
       " (8, 1632),\n",
       " (5, 6201),\n",
       " (9, 4319),\n",
       " (0, 14736)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point2.map(lambda x: (find_min_dist(bc_point_set.value, x), 1)).reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
