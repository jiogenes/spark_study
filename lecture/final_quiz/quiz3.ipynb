{"cells":[{"cell_type":"markdown","metadata":{"id":"TMRM053YFBL1"},"source":["### Data\n","Downloaded from: https://www.kaggle.com/unsdsn/world-happiness\n","\n","### Question 1.\n","\n","Summary of data set: The data set is a five-year survey of happiness of about 150 contries and some figures such as GDP or health level which are expected to have any correlation to happiness. Given data set includes 5 files in csv format named from 2015.csv to 2019.csv.\n","\n","Suppose that we want to find countries whose happiness scores does not decrease through those 5 years (i.e., equal to or greater than that of previous years).\n","\n","### 문제 1.\n","\n","데이터셋 요약: 5년간에 걸쳐 약 150개 국가에서 조사한 행복지수와 행복에 관련이 있을 것으로 예상되는 GDP나 건강과 같은 지수를 담고 있다. 2015년부터 2019년까지 조사결과가 각각 2015.csv ~ 2019.csv 파일에 들어있다. 매해 조사 국가가 조금씩 차이가 있으며 컬럼 가지수나 이름 또한 조금씩 다르다. 따라서 데이터를 분석하기 위해 컬럼이름을 직접 출력해보고 확인하여야 한다.\n","\n","첫번째 문제는 5년동안 행복지수가 지속적으로 상승하거나 적어도 전년도와 같은 나라를 찾는 것이다."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"H0SNTrxWFBL4"},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/24 16:05:55 WARN Utils: Your hostname, orange resolves to a loopback address: 127.0.1.1; using 166.104.246.51 instead (on interface enp15s0)\n","22/11/24 16:05:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["22/11/24 16:05:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["# create spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"my app\").master(\"local\").getOrCreate()\n","\n","# get context from the session\n","sc = spark.sparkContext"]},{"cell_type":"markdown","metadata":{"id":"BfPGBwLdFBL5"},"source":["(1) 2015.csv ~ 2019.csv의 파일 4개를 각각 data2015 ~ data2019 란 이름의 데이터프레임으로 읽어들이시오. 그리고 각 데이터프레임의 schema를 출력하시오. (10점)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"jgRWo0KDFBL5"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Country: string (nullable = true)\n"," |-- Region: string (nullable = true)\n"," |-- Happiness Rank: string (nullable = true)\n"," |-- Happiness Score: string (nullable = true)\n"," |-- Standard Error: string (nullable = true)\n"," |-- Economy (GDP per Capita): string (nullable = true)\n"," |-- Family: string (nullable = true)\n"," |-- Health (Life Expectancy): string (nullable = true)\n"," |-- Freedom: string (nullable = true)\n"," |-- Trust (Government Corruption): string (nullable = true)\n"," |-- Generosity: string (nullable = true)\n"," |-- Dystopia Residual: string (nullable = true)\n","\n","root\n"," |-- Country: string (nullable = true)\n"," |-- Region: string (nullable = true)\n"," |-- Happiness Rank: string (nullable = true)\n"," |-- Happiness Score: string (nullable = true)\n"," |-- Lower Confidence Interval: string (nullable = true)\n"," |-- Upper Confidence Interval: string (nullable = true)\n"," |-- Economy (GDP per Capita): string (nullable = true)\n"," |-- Family: string (nullable = true)\n"," |-- Health (Life Expectancy): string (nullable = true)\n"," |-- Freedom: string (nullable = true)\n"," |-- Trust (Government Corruption): string (nullable = true)\n"," |-- Generosity: string (nullable = true)\n"," |-- Dystopia Residual: string (nullable = true)\n","\n","root\n"," |-- Country: string (nullable = true)\n"," |-- Happiness.Rank: string (nullable = true)\n"," |-- Happiness.Score: string (nullable = true)\n"," |-- Whisker.high: string (nullable = true)\n"," |-- Whisker.low: string (nullable = true)\n"," |-- Economy..GDP.per.Capita.: string (nullable = true)\n"," |-- Family: string (nullable = true)\n"," |-- Health..Life.Expectancy.: string (nullable = true)\n"," |-- Freedom: string (nullable = true)\n"," |-- Generosity: string (nullable = true)\n"," |-- Trust..Government.Corruption.: string (nullable = true)\n"," |-- Dystopia.Residual: string (nullable = true)\n","\n","root\n"," |-- Overall rank: string (nullable = true)\n"," |-- Country or region: string (nullable = true)\n"," |-- Score: string (nullable = true)\n"," |-- GDP per capita: string (nullable = true)\n"," |-- Social support: string (nullable = true)\n"," |-- Healthy life expectancy: string (nullable = true)\n"," |-- Freedom to make life choices: string (nullable = true)\n"," |-- Generosity: string (nullable = true)\n"," |-- Perceptions of corruption: string (nullable = true)\n","\n","root\n"," |-- Overall rank: string (nullable = true)\n"," |-- Country or region: string (nullable = true)\n"," |-- Score: string (nullable = true)\n"," |-- GDP per capita: string (nullable = true)\n"," |-- Social support: string (nullable = true)\n"," |-- Healthy life expectancy: string (nullable = true)\n"," |-- Freedom to make life choices: string (nullable = true)\n"," |-- Generosity: string (nullable = true)\n"," |-- Perceptions of corruption: string (nullable = true)\n","\n"]}],"source":["from pyspark.sql.types import *\n","\n","# schema = StructType([\n","#     StructField('Country', StringType(), True),\n","#     StructField('Region', StringType(), True),\n","#     StructField('Happiness Rank', IntegerType(), True),\n","#     StructField('Happiness Score', DoubleType(), True),\n","#     StructField('Score', DoubleType(), True),\n","#     StructField('Standard Error', DoubleType(), True),\n","#     StructField('Economy (GDP per Capita)', DoubleType(), True),\n","#     StructField('Family', DoubleType(), True),\n","#     StructField('Health (Life Expectancy)', DoubleType(), True),\n","#     StructField('Freedom', DoubleType(), True),\n","#     StructField('Trust (Government Corruption)', DoubleType(), True),\n","#     StructField('Generosity', DoubleType(), True),\n","#     StructField('Dystopia Residual', DoubleType(), True),\n","# ])\n","\n","data2015 = spark.read.format('csv')\\\n","                    .option('header', 'true')\\\n","                    .option(\"quote\", \"\\\"\")\\\n","                    .option(\"escape\", \"\\\"\")\\\n","                    .option(\"multiLine\", \"true\")\\\n","                    .load('../../data/WorldHapinessReport/2015.csv')\n","\n","data2016 = spark.read.format('csv')\\\n","                    .option('header', 'true')\\\n","                    .option(\"quote\", \"\\\"\")\\\n","                    .option(\"escape\", \"\\\"\")\\\n","                    .option(\"multiLine\", \"true\")\\\n","                    .load('../../data/WorldHapinessReport/2016.csv')\n","\n","data2017 = spark.read.format('csv')\\\n","                    .option('header', 'true')\\\n","                    .option(\"quote\", \"\\\"\")\\\n","                    .option(\"escape\", \"\\\"\")\\\n","                    .option(\"multiLine\", \"true\")\\\n","                    .load('../../data/WorldHapinessReport/2017.csv')\n","\n","data2018 = spark.read.format('csv')\\\n","                    .option('header', 'true')\\\n","                    .option(\"quote\", \"\\\"\")\\\n","                    .option(\"escape\", \"\\\"\")\\\n","                    .option(\"multiLine\", \"true\")\\\n","                    .load('../../data/WorldHapinessReport/2018.csv')\n","\n","data2019 = spark.read.format('csv')\\\n","                    .option('header', 'true')\\\n","                    .option(\"quote\", \"\\\"\")\\\n","                    .option(\"escape\", \"\\\"\")\\\n","                    .option(\"multiLine\", \"true\")\\\n","                    .load('../../data/WorldHapinessReport/2019.csv')\n","\n","data2015.printSchema()\n","data2016.printSchema()\n","data2017.printSchema()\n","data2018.printSchema()\n","data2019.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"7tbd7XCxFBL9"},"source":["(2) 5년간의 데이터프레임에서 나라와 행복지수를 뽑아 키-값의 쌍 (즉, (나라, 행복지수))의 RDD로 생성하시오. 그리고 5개의 RDD를 rdd15 ~ rdd19이란 이름 변수에 저장하시오. 위에서 말했듯이 나라이름이 Country나 Country or region와 같은 이름의 컬럼으로 들어가 있으므로 확인하고 처리해야 할 것이다. (10점)\n","\n","힌트: 혹시 dataframe select를 하려면 Happiness.Score와 같이 column name에 점(.)이 있으면 Happiness를 table name으로 인식하기 때문에 이를 escape해주어야 한다. select시 column name을 \"\\`Happiness.Score\\`\" 와 같이 reverse single quotation mark (\\`)로 감싸주면 된다. 하지만 dataframe select를 하지 않는 방법도 있고 코드도 더 간단하다."]},{"cell_type":"code","execution_count":49,"metadata":{"id":"VmsDV9WzFBL9"},"outputs":[],"source":["rdd15 = data2015.rdd.map(lambda x: (x[0], float(x[3])))\n","rdd16 = data2016.rdd.map(lambda x: (x[0], float(x[3])))\n","rdd17 = data2017.rdd.map(lambda x: (x[0], float(x[3])))\n","rdd18 = data2018.rdd.map(lambda x: (x[1], float(x[2])))\n","rdd19 = data2019.rdd.map(lambda x: (x[1], float(x[2])))"]},{"cell_type":"markdown","metadata":{"id":"4fM87VCEFBL-"},"source":["(3) cogroup 이용해 연속된 두 해의 RDD, rdd15와 rdd16에서 같은 키 (즉, 나라)를 갖는 두 해의 행복지수를 묶어 2015 년도에 비해 2016 년도에 행복지수가 증가하거나 적어도 같은 나라를 filtering할 수 있다. 이러한 나라에 대해 (나라, 2016년도의 행복지수)의 키-값의 쌍 RDD를 생성해 rdd란 이름으로 저장하시오. (15점) \n","\n","주의: 해마다 조사국가가 조금씩 차이가 있으므로 5년간 모두 행복지수 값이 존재하는 국가만을 대상으로 한다. 즉, cogroup시 행복지수가 없으면 filter out시켜야 할 것이다.\n","\n","힌트: cogroup을 한 뒤 행복지수가 없는 나라를 판단해 (즉, 길이 > 0) filter한 뒤 각 나라마다 두 해의 행복지수를 비교해 filter를 한뒤 다시 map을 이용해 (나라, 2016년 행복지수)의 키-값 쌍 RDD를 생성한다. 값으로 2016년 행복지수를 놓는 이유는 다음 문제(4)에서 다시 rdd와 그 다음해에 대해 재귀적으로 연산을 처리하기 위함이다."]},{"cell_type":"code","execution_count":53,"metadata":{"id":"FWWcS3T6FBL-"},"outputs":[{"data":{"text/plain":["[('Finland', 7.413),\n"," ('Australia', 7.313),\n"," ('Argentina', 6.65),\n"," ('Uruguay', 6.545),\n"," ('Thailand', 6.474)]"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["rdd = rdd15.cogroup(rdd16).map(lambda x: (x[0], tuple(map(list, x[1])))).filter(lambda x: len(x[1]) == 2 and len(x[1][0]) > 0 and len(x[1][1]) > 0 and x[1][0] <= x[1][1]).map(lambda x: (x[0], x[1][1][0]))\n","rdd.take(5)"]},{"cell_type":"markdown","metadata":{"id":"XK0oTXY-FBL-"},"source":["(4) 이 rdd를 다음 3개 rdd (즉, rdd17, rdd18, rdd19)와 위와 같은 연산을 연달아 수행하여 최종적으로 5년간 행복지수가 지속적으로 증가하거나 적어도 감소하지 않는 나라를 출력하시오. (15점)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"XZc0DDGFFBL-"},"outputs":[{"data":{"text/plain":["[('Cambodia', 4.7),\n"," ('Congo (Brazzaville)', 4.812),\n"," ('Finland', 7.769),\n"," ('Poland', 6.182),\n"," ('Romania', 6.07)]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["rdd = rdd.cogroup(rdd17).map(lambda x: (x[0], tuple(map(list, x[1])))).filter(lambda x: len(x[1]) == 2 and len(x[1][0]) > 0 and len(x[1][1]) > 0 and x[1][0] <= x[1][1]).map(lambda x: (x[0], x[1][1][0]))\n","rdd = rdd.cogroup(rdd18).map(lambda x: (x[0], tuple(map(list, x[1])))).filter(lambda x: len(x[1]) == 2 and len(x[1][0]) > 0 and len(x[1][1]) > 0 and x[1][0] <= x[1][1]).map(lambda x: (x[0], x[1][1][0]))\n","rdd = rdd.cogroup(rdd19).map(lambda x: (x[0], tuple(map(list, x[1])))).filter(lambda x: len(x[1]) == 2 and len(x[1][0]) > 0 and len(x[1][1]) > 0 and x[1][0] <= x[1][1]).map(lambda x: (x[0], x[1][1][0]))\n","rdd.take(5)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["['Cambodia',\n"," 'Congo (Brazzaville)',\n"," 'Finland',\n"," 'Poland',\n"," 'Romania',\n"," 'Cameroon',\n"," 'Chad',\n"," 'Mongolia',\n"," 'Niger',\n"," 'Burkina Faso',\n"," 'Benin',\n"," 'Togo',\n"," 'Senegal',\n"," 'Madagascar',\n"," 'Portugal',\n"," 'Estonia',\n"," 'Gabon',\n"," 'Hungary',\n"," 'Ivory Coast',\n"," 'Latvia',\n"," 'Malta',\n"," 'Czech Republic',\n"," 'Tajikistan',\n"," 'Honduras']"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["rdd.map(lambda x: x[0]).collect()"]},{"cell_type":"markdown","metadata":{"id":"fbgYatmtFBL_"},"source":["### Question 2.\n","\n","Compute Pearson correlation between happiness score (H) and each of four factors, which are GDP per capita (GDP), health (HL), freedom (FD) and generosity (G). The equation calculating Pearson correlation between two columns is\n","\n","\\begin{equation*}\n","P_{X, Y} = \\frac{1}{n-1} \\sum_{i = 1}^n \\left( \\frac{x_i - \\mu_x}{\\sigma_x} \\right) \\left( \\frac{y_i - \\mu_y}{\\sigma_y} \\right)\n","\\end{equation*}\n","\n","where $X = \\{ x_1, ..., x_n \\}$ and $Y = \\{ y_1, ..., y_n \\}$ represet sets of two attributes such that $x_i$ and $y_i$ are corresponding columns of the i-th row. Furthermore, $\\mu_x$ and $\\sigma_x$ denote mean and standard deviation of the corresponding column respectively.\n","\n","Compute Pearson correlations $P_{H, GDP}$, $P_{H, HL}$, $P_{H, FD}$ and $P_{H, G}$ by filling the following blank cells.\n","\n","### 문제 2.\n","\n","5해에 걸친 조사를 통합하여 행복지수(H)와 다른 네가지 요인, 인구당 GDP(GDP) 및 건강(HL), 자유도(FD), 관용도(G) 간의 피어슨 상관계수 (Pearson correlation)을 게산하시오. 계산 식은 다음과 같다.\n","\n","\\begin{equation*}\n","P_{X, Y} = \\frac{1}{n-1} \\sum_{i = 1}^n \\left( \\frac{x_i - \\mu_x}{\\sigma_x} \\right) \\left( \\frac{y_i - \\mu_y}{\\sigma_y} \\right)\n","\\end{equation*}\n","\n","단, 위 식에서 $X = \\{ x_1, ..., x_n \\}$와 $Y = \\{ y_1, ..., y_n \\}$가 나타내는 것은 두 개의 요인(즉, 칼럼)에 대한 i번째 row의 해당 값을 말한다. 또한 $\\mu_x$와 $\\sigma_x$는 해당 칼럼의 평균과 표준편차를 의미한다.\n","\n","아레 셀을 채워 가며 피어슨 상관계수 $P_{H, GDP}$ 및 $P_{H, F}$, $P_{H, HL}$, $P_{H, FD}$, $P_{H, G}$을 계산하시오."]},{"cell_type":"markdown","metadata":{"id":"hsPOCrSeFBL_"},"source":["(5) 우선 5개의 데이터프레임 data2015 ~ data2019에서 \\[H, GDP, HL, FD, G\\]의 numpy arrray로 이루어진 RDD들을 각각 구한 후 모두 union하여 합치시오. 통합한 RDD의 이름은 rdd로 정하시오. 각 데이터프레임 마다 해당 칼럼 이름이 조금씩 다르므로 schema를 보고 적절히 뽑아와야 한다. (10점)\n","\n","참고: numpy array를 각 elelement로 갖는 RDD를 이용하면 다섯 가지 칼럼의 계산을 한꺼번에 수행할 수 있어 매우 편하다. 예를 들어 numpy array 로 아래와 같은 계산이 가능하다.\n","\n","Code:\n","````python\n","import numpy as np\n","\n","x = np.array([ 1.0, 2.0, 3.0 ], dtype=np.float16)\n","y = np.array([ 3.0, 2.0, 1.0 ], dtype=np.float16)\n","\n","print(\"x + y = {}\".format(x + y))\n","print(\"x * y = {}\".format(x * y))\n","````\n","Output:\n","````\n","x + y = [4. 4. 4.]\n","x * y = [3. 4. 3.]\n","````\n","\n","RDD의 element에 4개 칼럼의 값을 numpy array로 넣어두면 .count(), .sum(), .mean(), .stdev() 등의 action을 수행하면 각 칼럼마다의 연산이 한꺼번에 수행된다."]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","rdd15 = data2015.select('Happiness Score', 'Economy (GDP per Capita)', 'Health (Life Expectancy)', 'Freedom', 'Generosity').rdd.map(lambda x: np.array(list(map(float, x))))\n","rdd16 = data2016.select('Happiness Score', 'Economy (GDP per Capita)', 'Health (Life Expectancy)', 'Freedom', 'Generosity').rdd.map(lambda x: np.array(list(map(float, x))))\n","rdd17 = data2017.select('`Happiness.Score`', '`Economy..GDP.per.Capita.`', '`Health..Life.Expectancy.`', 'Freedom', 'Generosity').rdd.map(lambda x: np.array(list(map(float, x))))\n","rdd18 = data2018.select('Score', 'GDP per capita', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity').rdd.map(lambda x: np.array(list(map(float, x))))\n","rdd19 = data2019.select('Score', 'GDP per capita', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity').rdd.map(lambda x: np.array(list(map(float, x))))\n","rdd = rdd15.union(rdd16).union(rdd17).union(rdd18).union(rdd19)"]},{"cell_type":"markdown","metadata":{"id":"GM12hHAqFBMA"},"source":["(6) n (= 조사 데이터의 개수)을 구하시오. Action 사용. (5점)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"MVP17h5PFBMA"},"outputs":[{"data":{"text/plain":["782"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["count = rdd.count()\n","count"]},{"cell_type":"markdown","metadata":{"id":"6lIehq2uFBMA"},"source":["(7) rdd의 튜플의 평균을 계산하시오. (10점)"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"rctydC91FBMA"},"outputs":[{"data":{"text/plain":["array([5.3790179 , 0.91604748, 0.61241558, 0.41109083, 0.21857584])"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["m = rdd.reduce(lambda x, y: x + y) / count\n","m"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"data":{"text/plain":["array([-0.01378765, -0.00234834, -0.00156981, -0.00105406, -0.00056012])"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["rdd.reduce(lambda x, y: (x - m)/count + (y - m)/count)"]},{"cell_type":"markdown","metadata":{"id":"IrfmH9qLFBMA"},"source":["(8) rdd의 표준편차를 계산하시오. (10점)"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"h2sM7GijFBMA"},"outputs":[{"data":{"text/plain":["array([0.00972759, 0.00165663, 0.00110753, 0.00074344, 0.00039528])"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["V = rdd.reduce(lambda x, y: np.power((x - m) / count, 2) + np.power((y - m) / count, 2))\n","sigma = np.sqrt(V)\n","sigma"]},{"cell_type":"markdown","metadata":{"id":"bPA8yysNFBMA"},"source":["(9) map과 reduce를 이용해 피어슨 상관관계 (4개)를 numpy array로 한꺼번에 계산하시오. (10점)\n","\n","힌트: map으로 numpy array x의 $(x - \\mu_x) / \\sigma_x$를 계산한 다음, 다시 map으로 <code>[ x[0] * t for in arr[1:] ]</code> 를 계산해 numpy arrray로 만들어준 다음 sum을 구하면 피어슨 상관관계식의 시그마 식 부분을 구할 수 있다.\n","\n","\\begin{equation*}\n","P_{X, Y} = \\frac{1}{n-1} \\sum_{i = 1}^n \\left( \\frac{x_i - \\mu_x}{\\sigma_x} \\right) \\left( \\frac{y_i - \\mu_y}{\\sigma_y} \\right)\n","\\end{equation*}"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"5WihdRhiGoWx"},"outputs":[{"data":{"text/plain":["array([0.15730479, 0.12246554, 0.2300549 , 0.01792568])"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["rdd.map(lambda x: (x - m)/sigma).map(lambda x: np.array([x[0] * t for t in x[1:]])).reduce(lambda x, y: (x + y)/(count-1))"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.13 ('spark')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"}}},"nbformat":4,"nbformat_minor":0}
