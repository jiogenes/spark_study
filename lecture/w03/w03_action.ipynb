{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('Action') \\\n",
    "        .config('spark.ui.port', '4050') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Operations\n",
    "### Transpormations (define a new RDD)\n",
    "-  map, filter, flatMap, reduceByKey, groupByKey, sortByKey, union, join etc...\n",
    "###  Actions (return a result to driver program)\n",
    "-  collect (실습할 때 가장많이 사용할 것)\n",
    "-  reduce (결과값을 바로 프린트해볼 수 있음. transpormation의 reduceByKey와 헷갈리지 않도록 주의)\n",
    "-  count, save, lookupKey etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(1, 11), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce(func)\n",
    "매개변수로 들어가는 함수를 사용해 RDD를 단일객체가 될 때 까지 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduce = data.reduce(lambda x, y: x + y)\n",
    "data_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect()\n",
    "데이터 셋의 전체를 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count()\n",
    "RDD의 element 개수를 샌다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first()\n",
    "데이터셋에서 처음 1개의 element를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take(n)\n",
    "데이터셋에서 처음 n개의 elements를 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## takeSample(withReplacement, num, seed=None)\n",
    "- RDD에서 랜덤한 샘플을 뽑아 드라이버로 반환\n",
    "- 매개변수\n",
    "  - withReplacement : True -> 복원추출, False -> 비복원추출\n",
    "  - num : sample 크기\n",
    "  - seed : seed 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 10, 7]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.takeSample(False, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## takeOrdered()\n",
    "- RDD에서 작은 순서대로 지정한 개수를 리턴\n",
    "- 작은 데이터를 다룰때만 빠르고 큰 데이터에서는 `sort()`를 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 8]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "data2 = sc.parallelize(range(10, 0, -1), 1)\n",
    "print(data2.take(3))\n",
    "print(data2.takeOrdered(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saveAsTextFile(path)\n",
    "- 데이터셋 파티션 하나당 하나의 파일로 저장\n",
    "- 매개변수\n",
    "  - path : 저장될 디렉토리이름\n",
    "  - local filesystem, HDFS 등의 파일 시스템에 저장 가능 ex) `hdfs:...`\n",
    "- 각각의 element를 하나의 line로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.saveAsTextFile('save_test')\n",
    "data_reread = sc.textFile('save_test')\n",
    "data_reread.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## countByKey()\n",
    "- key-value 쌍으로 이루어진 RDD에서 작동하며, key를 기준으로 개수를 센다\n",
    "- 각 key의 count를 갖는 dictionary를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 2, 'b': 1, 'c': 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([('a', 1), ('b', 2), ('c', 3), ('a', 4)])\n",
    "data.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
