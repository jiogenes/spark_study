{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('Transformation') \\\n",
    "        .config('spark.ui.port', '4050') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpormations (define a new RDD)\n",
    "-  RDD를 변경하는 작업들\n",
    "-  결과물로 다시 RDD가 생성\n",
    "-  e.g., map(), flatMap(), sample(), reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(1, 11), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map(func)\n",
    "- RDD의 각 element에 함수 func를 적용하여 새로운 RDD를 리턴한다.\n",
    "- 각 element에 하나씩 mapping되는 값을 반환하므로 1:1 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(1, 11), 1)\n",
    "data = data.map(lambda x: x + 1)\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter(func)\n",
    "- 전달된 함수의 조건에 따라 통과한 값만 출력 -> 반드시 bool 값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(1, 11), 1)\n",
    "filtered = data.filter(lambda x: x < 5)\n",
    "filtered.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatMap(func)\n",
    "- `map()`과 비슷하나 element하나를 받아서 0, 1개 혹은 복수개를 출력할 수 있다. 즉 1:다 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1], [2, 4], [3, 9], [4, 16]]\n",
      "[1, 1, 2, 4, 3, 9, 4, 16]\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize([1, 2, 3, 4], 1)\n",
    "print(data.map(lambda x: [x, x*x]).collect())\n",
    "print(data.flatMap(lambda x: [x, x*x]).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapPartitions(func)\n",
    "- RDD의 각 파티션에 대해 map을 실행. 다:1(partition 갯수)\n",
    "- 활용성은 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 15, 34]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(1, 11), 3)\n",
    "def f(x): yield sum(x)\n",
    "data.mapPartitions(f).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapValues(func)\n",
    "- 키-값 쌍 RDD에 대해 값에 대해서만 func를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 3), ('b', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([('a', ['apple', 'banana', 'lemon']), ('b', ['grape'])])\n",
    "def f(x): return len(x)\n",
    "data.mapValues(f).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduceByKey(func, [numPartitions])\n",
    "- key별로 func를 수행\n",
    "- numPartitions: 결과로 생성되는 RDD의 파티션 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 5), ('b', 2), ('c', 3)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([('a', 1), ('b', 2), ('c', 3), ('a', 4)])\n",
    "data.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d3673617709ceda87ac6d055fc19541640288a4bee74fd36c0e58c49d867a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
